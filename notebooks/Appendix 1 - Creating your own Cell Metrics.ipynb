{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdeeeb01-782e-45d4-b99c-9d983d575e4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Appendix 1 - Creating your own Cell Metrics\n",
    "\n",
    "**Estimated time to run through notebook is 20 minutes** \n",
    "\n",
    "\n",
    "Chapter 4 showed how to visualize and analyze existing cell metrics. This notebook focuses on how to use image data to create a new cell metric for a classifier.\n",
    "\n",
    "This notebook shows how to:\n",
    "-  [sample image and explore image data](#distance)\n",
    "-  [create a metric for nuclear volume from the nuclear segmentation channel](#nuclearvolume) \n",
    "(How to read images and perform simple operations on a CZYX array)\n",
    "-  [create a metric for distance between cell membrane and nucleus](#membranenucleusdistance)\n",
    "(How to parallelize read operations and read multiple channels)\n",
    "-  [create a metric for the percentage volume of a cell that is occupied by microtubules](#percentvolume)\n",
    "(How to create a metric that could be of biological relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fe9d85-648a-4de0-808e-8d504e7bc27b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <a id='preprocessing'></a>Load libraries and manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366be8b-b474-4840-b5be-9941a57e5f0d",
   "metadata": {},
   "source": [
    "The following cell loads the relevant libraries and the manifest containing the images we will be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf7855-beed-481d-b652-96ac6fd8cb7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from aicsimageprocessing import diagnostic_sheet, read_ome_zarr, rescale_image, imgtoprojection\n",
    "from upath import UPath as Path\n",
    "import warnings\n",
    "from aicsimageio import transforms, AICSImage\n",
    "import nbvv\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "# df = pd.read_parquet(\"s3://allencell-cytodata-variance-data/processed/hackathon_manifest_09292022.parquet\")\n",
    "df = pd.read_parquet(\"s3://allencell-cytodata-variance-data/processed/hackathon_manifest_092022.parquet\")\n",
    "print(f'Number of cells: {len(df)}')\n",
    "print(f'Number of columns: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3752a-407c-47a3-b5d9-86bb73401a15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <a id='distance'></a> Sample Image and Explore Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f33ae5-540f-44cf-a53f-0c78d60ad697",
   "metadata": {},
   "source": [
    "Similar to Chapter 3, we will be sampling images and exploring their different channels. The following code cell samples a cell image and uses the read_ome_zarr function from AICSImageIO to obtain the image data in CZYX shape. img_data is an image representation of shape CZYX - where C is the channel, and Z, Y and X are the spatial dimensions. \n",
    "\n",
    "Note - you can pass in \"level = 2\" as a parameter in  read_ome_zarr for lower resolution images.\n",
    "\n",
    "Voxel Sizes are  0.108333<sup>3</sup> ùúám<sup>3</sup>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e1776-19e1-4546-81d0-0a624b0c5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_cell = df.sample(1).iloc[0]\n",
    "# full_img = read_ome_zarr(some_cell[\"registered_path\"], level = 2)\n",
    "full_img = read_ome_zarr(some_cell[\"registered_path\"])\n",
    "img_data = full_img.data.squeeze()\n",
    "img_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f6f0e-242f-449a-b109-0e9ae3e61b90",
   "metadata": {},
   "source": [
    "Here, we see that images have 7 channels. They are \n",
    "\n",
    "- bf - brightfield channel \n",
    "- dna - dna intensity channel\n",
    "- membrane - membrane intensity channel\n",
    "- structure - structure intensity channel\n",
    "- dna_segmentation - segmentation of the dna channel\n",
    "- membrane_segmentation - segmentation of the membrane channel\n",
    "- struct_segmentation_roof - segmentation of the structure channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993863d-551b-4b08-b40f-d55c05f54c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Images have 7 channels for brightfield + DNA, membrane, and structure intensity and segmentation channels\n",
    "full_img.channel_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8334dc-676f-4701-84ae-fc856b4ea503",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <a id='nuclearvolume'></a> Metric 1: Nuclear Volume\n",
    "This example is focused on how to read images and perform simple operations on an array containing image data. We will be building a basic cell metric to compute nuclear volume using the dna_segmentation channel which tells us the size and location of the nucleus in a cell image. img_data[4] corresponds to the segmentation of the dna channel and we collect the nuclear pixels using np.nonzero(to count pixels of value 1) and np.transpose(to get the pixel locations in a more readable format). We then find the nuclear volume by multiplying the number of pixels we find by the voxel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496e0c1-fe05-45bf-988e-20887e4a6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "some_cells = df.sample(count)\n",
    "tic = time.perf_counter()\n",
    "for index in range(count): \n",
    "    full_img = read_ome_zarr(some_cells.iloc[index][\"registered_path\"]) # returns AICS Image\n",
    "    img_data = full_img.data.squeeze() #returns 4D CZYX array\n",
    "    nuclear_pixels = np.transpose(np.nonzero(img_data[4])) #img_data[4] corresponds to the dna_segmentation channel\n",
    "    #print(\"Total Number of non-zero elements is: \", len(nuclear_pixels))\n",
    "    nuc_volume = len(nuclear_pixels) * 0.10833 * 0.10833 * 0.10833\n",
    "    print(\"Calculated Nuclear Volume is \", nuc_volume, \" cubic microns.\")\n",
    "    print(f\"Pre-computed Nuclear Volume is {some_cells['nuclear_volume'].values[0]} cubic microns\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b021cb-9330-4084-b350-3cdc640c2884",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <a id='membranenucleusdistance'></a> Metric 2: Distance between Cell Membrane and Nucleus \n",
    "\n",
    "This metric example is distance between the nucleus and the cell membrane. We will be using two channels, the membrane segmentation and the DNA segmentation, in order to determine the closest points between our two cellular structures. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235dc86f-d9a5-440b-9604-4ed115c4d03e",
   "metadata": {},
   "source": [
    "Our first step is to find the edges of the cell membrane and nucleus and then compute the minimum distance between any pair of points on the two edges. The following cell will be a 2D illustration of how we go about edge detection and collection. We will be using the [binary_erosion](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.binary_erosion.html) operation to compute the edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7369b093-00fd-402d-a1fd-f15524a1decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "from scipy import ndimage\n",
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "\n",
    "nuc_seg = img_data[4].max(axis=0) \n",
    "mask =  ndimage.binary_erosion(nuc_seg.tolist())\n",
    "nuc_seg[mask]=0 \n",
    "\n",
    "cell_seg = img_data[5].max(axis=0) \n",
    "mask =  ndimage.binary_erosion(cell_seg.tolist())\n",
    "cell_seg[mask]=0 \n",
    "\n",
    "\n",
    "dna_seg = img_data[4].max(axis = 0)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(dna_seg)\n",
    "plt.title('Segmentation of the DNA Channel')\n",
    "plt.subplots_adjust(wspace=0.5,hspace=0.4)\n",
    "\n",
    "#Membrane Segmentation Plot\n",
    "membrane_segmentation = img_data[5].max(axis = 0)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(membrane_segmentation)\n",
    "plt.title('Segmentation of the Membrane Channel')\n",
    "\n",
    "\n",
    "dna_seg = img_data[4]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(nuc_seg)\n",
    "plt.title('Edges of the DNA Channel')\n",
    "plt.subplots_adjust(wspace=0.5,hspace=0.4)\n",
    "\n",
    "#Membrane Segmentation Plot\n",
    "membrane_segmentation = img_data[5]\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(cell_seg)\n",
    "plt.title('Edges of the Membrane Channel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439c918-0eb5-42ad-b064-24496075e15d",
   "metadata": {},
   "source": [
    "### Parallelizing Image Reads and 3D Distance Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f28c9-ebe5-4c39-af42-8d0c51e317a7",
   "metadata": {},
   "source": [
    "We use the AICSImageIO function read_ome_zarr to go from an AICSImage to a CZYX array, however this step can be time-consuming particularly when trying to generate a metric over a large dataset. To speed this up, we will use the concurrent.futures module and threads to parallelize the bottleneck step of reading in images. Next, we will perform the same binary erosion operation seen in the previous cell on 3D images to identify the edges. Once we have the set of nucleus and membrane edges, we will use a kdTree to find the minimum distance between points in the two sets of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb24a27-1e68-4087-9e41-75e20d50c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed \n",
    "from scipy.spatial import cKDTree\n",
    "import time\n",
    "count = 1\n",
    "some_cells = df.sample(count)\n",
    "tic = time.perf_counter()\n",
    "chosen_images = []\n",
    "images_data = []\n",
    "some_cells['Membrane-Nucleus Distance'] = 0.0\n",
    "#ThreadPoolExecutor uses a pool of threads to execute calls asynchronously.\n",
    "with ThreadPoolExecutor() as executor: \n",
    "    for index in range(count): \n",
    "        #executor.submit schedules the callable, fn, to be executed and and returns a Future object representing the execution of the callable.\n",
    "        # full_img = executor.submit(read_ome_zarr, some_cells.iloc[index][\"registered_path\"], level = 2)\n",
    "        full_img = executor.submit(read_ome_zarr, some_cells.iloc[index][\"registered_path\"])\n",
    "        chosen_images += [full_img]\n",
    "        \n",
    "    for index, image in enumerate(as_completed(chosen_images)): \n",
    "        full_img = image\n",
    "        #print(full_img)\n",
    "        img_data = full_img.result().data.squeeze()\n",
    "        images_data += [img_data]\n",
    "\n",
    "        nuc_edges = img_data[4]\n",
    "        mask =  ndimage.binary_erosion(nuc_edges.tolist())\n",
    "        nuc_edges[mask]=0 \n",
    "        nuc_edges = np.transpose(np.nonzero(nuc_edges))\n",
    "        #print(nuc_edges)\n",
    "                \n",
    "        cell_edges = img_data[5]\n",
    "        mask =  ndimage.binary_erosion(cell_edges.tolist())\n",
    "        cell_edges[mask]=0 \n",
    "        cell_edges = np.transpose(np.nonzero(cell_edges))\n",
    "        min_dists, min_dist_idx = cKDTree(cell_edges).query(nuc_edges, 1)\n",
    "        min_dist = min(min_dists)\n",
    "        some_cells.at[some_cells.index[index], 'Membrane-Nucleus Distance'] = min_dist        \n",
    "print(some_cells['Membrane-Nucleus Distance'].value_counts())\n",
    "toc = time.perf_counter()\n",
    "print(f\" took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94627ce1-6b2d-4c0e-8eef-a744c42a1466",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <a id='percentvolume'></a>Metric 3: Percentage of Cell Volume occupied by Microtubules\n",
    "\n",
    "This example is focused on how to making a metric of biological relevance. We will be utilizing the structure channel and selecting images with \"microtubules\" as its imaged structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2cf2d2-c01e-42b8-8657-02f6b3d1b0cd",
   "metadata": {},
   "source": [
    "Our goal is to classify cell stage based on microtubules present in a cell. To do this, we will begin by creating a dataset with equal number of elements in each cell stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8ca39-e953-4f8d-bf7b-114b75a50101",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_cells = df.loc[df['Structure']=='microtubules']\n",
    "min_count = some_cells['cell_stage'].value_counts().min() #min_count refers to the minimum number of images present in a cell stage\n",
    "n = min_count \n",
    "cells_to_include=[]\n",
    "for name, group in some_cells.groupby('cell_stage'):    \n",
    "    sampled_group = group.sample(n) \n",
    "    cells_to_include.append(sampled_group)\n",
    "df_mitocells = pd.concat(cells_to_include).reset_index(drop=True)\n",
    "# Discarding all the M6M7_single cells\n",
    "df_mitocells = df_mitocells.drop(df_mitocells[df_mitocells['cell_stage']=='M6M7_single'].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768bd24-bd12-4325-aa70-bdd797d190f5",
   "metadata": {},
   "source": [
    "The following cell samples images from our new dataset and the number of images we take in is defined by the variable count. We then identify the number of microtubule pixels and the number of overall cell pixels. Using these two values, we find the percentage volume of the cell that is made up of microtubules, with the idea that there may be some biological relevance to higher microtubule density at a particular cell stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f8f2ce-9fd2-457f-96f5-38d2b4ae4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "count = 80\n",
    "some_cells = df_mitocells.sample(count)\n",
    "tic = time.perf_counter()\n",
    "some_cells = some_cells.set_index('CellId')\n",
    "some_cells['Percentage Volume'] = 0\n",
    "some_cells['Microtubule Pixels'] = 0\n",
    "#Microtubules\n",
    "chosen_images = {}\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for sample_number in range(count): \n",
    "        full_img = executor.submit(read_ome_zarr, some_cells.iloc[sample_number][\"registered_path\"])\n",
    "        chosen_images[some_cells.index[sample_number]] = full_img\n",
    "    for image_num, index in enumerate(chosen_images): \n",
    "        full_img = chosen_images[index]\n",
    "        img_data = full_img.result().data.squeeze()\n",
    "        #Nuc_edges = microtubules\n",
    "        microtubule_pixels=np.transpose(np.nonzero(img_data[6]))\n",
    "        cell_pixels=np.transpose(np.nonzero(img_data[5]))\n",
    "        metric = 100* (len(microtubule_pixels)/len(cell_pixels))\n",
    "        some_cells.at[index, 'Percentage Volume'] = metric\n",
    "        if image_num%20==0: print(\"Image \",image_num) #print statement to track progress\n",
    "toc = time.perf_counter()\n",
    "print(f\" took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e179e-f8d5-42d1-bcde-a77723e38207",
   "metadata": {},
   "source": [
    "The following cell is a violin plot of how percentage volume changes across different cell stages. You can edit the metric variable and see how other metrics such as \"Microtubule Pixels\" change across different cell stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eaaee5-e64a-4f16-8053-a4e569f9f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "metric = \"Percentage Volume\" #  metric to plot\n",
    "stratifier = \"cell_stage\" #  name of column whose values are used to define sub-populations\n",
    "\n",
    "order = np.sort(some_cells[stratifier].unique())\n",
    "fig, axes = plt.subplots(figsize=(10, 5), dpi=100)\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "sns.violinplot(\n",
    "    y=stratifier,\n",
    "    x=metric,\n",
    "    order = order,\n",
    "    data=some_cells,\n",
    "    scale=\"width\",\n",
    "    ax=axes\n",
    ")\n",
    "\n",
    "axes.set_title(f\"{metric} across {stratifier}\")\n",
    "axes.grid(True, which=\"major\", axis=\"both\")\n",
    "axes.set_axisbelow(True)\n",
    "axes.set_ylabel(\"Cell Stage\")\n",
    "axes.set_xlabel(\"Percentage Volume\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4c74c-fd30-48b0-a012-5b9b3f895958",
   "metadata": {},
   "source": [
    "## <a id='conclusion'></a> Conclusion\n",
    "\n",
    "In this appendix we explained how to create a new metric and demonstrated various ways to access and analyze data from image channels. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
