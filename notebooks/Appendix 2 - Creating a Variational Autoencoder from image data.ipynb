{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7684b418-54aa-41cb-b800-b5d91414e0f5",
   "metadata": {},
   "source": [
    "# Appendix 2 - Creating a Variational Autoencoder from image data\n",
    "**Estimated time to run through notebook is 20 minutes** \n",
    "\n",
    "This notebook shows how to\n",
    "-  [Load libraries, predefine some functions, and load the manifest ](#preprocessing) \n",
    "-  [5.1 Parametrize and train a 3D Image VAE using serotiny's yamls](#param)\n",
    "-  [5.2 Load and test a trained model](#embed)\n",
    "-  [5.3 Train a VAE on 2D images](#train2D)\n",
    "-  [Conclusion](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c71778-2f00-4071-b85c-99a552b1a5f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a id='preprocessing'></a>Load libraries, predefine some functions, and load the manifest \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3d387-c4d8-4d9e-b925-1e4c4af4a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from upath import UPath as Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nbvv\n",
    "\n",
    "from serotiny.io.image import image_loader\n",
    "from cytodata_aics.io_utils import rescale_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8edef0-f8a8-46b2-a634-108b008c47cf",
   "metadata": {},
   "source": [
    "For this task, lets use the edge vs non-edge cell dataset we created in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7043a5-a69c-4089-b083-55f7867f8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_edgeVSnoedge = pd.read_csv('/home/aicsuser/serotiny_data/cells_edgeVSnoedge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8cf3e-2646-429b-983e-fb1839370b0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a id='param'></a>5.1 Parametrize a VAE using serotiny's yamls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f9a2b6-e5a9-46c3-9c40-9315426a83a7",
   "metadata": {},
   "source": [
    "To parametrize an image based VAE (Variational Autoencoder), we will call `serotiny.models.vae.ImageVAE`. This class takes the follwing arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d57fe-c172-44d7-b3af-8edbf577d6c7",
   "metadata": {},
   "source": [
    "```yaml\n",
    "latent_dim: int - The number of latent dimensions e.g. 512\n",
    "in_channels: int - The number of channels in the input image e.g. 1\n",
    "hidden_channels: list - The number of convolutional filters to apply in sequence e.g [2,2,2,2]\n",
    "max_pool_layers: list - The indices where max pooling is applied e.g. [2]\n",
    "input_dims: list - The shape of the input image e.g. [238, 374]\n",
    "x_label: str - The string key of the input being passed in e.g. \"image\"\n",
    "optimizer: torch.optim.Optimizer -  the optimizer to use e.g. torch.optim.Adam\n",
    "beta: int - the beta term weighting the KL term relative to reconstruction loss e.g. 1.0\n",
    "id_label: str - The string key associated with an id label e.g. \"id\" \n",
    "non_linearity: Optional[nn.Module] - The non linearity used in convolutional blocks e.g. torch.nn.ReLU\n",
    "decoder_non_linearity: Optional[nn.Module] - A decoder non linearity to apply after decoding e.g. torch.nn.Sigmoid\n",
    "reconstruction_loss: nn.MSELoss(reduction=\"none\") - the reconstruction loss to use e.g. torch.nn.MSELoss\n",
    "skip_connections: bool - whether to use skip connections or not - e.g. False\n",
    "batch_norm: bool -  whether to use batch norm or not - e.g. True\n",
    "mode: str - whether the input image is 2d or 3d - e.g. 2d\n",
    "prior: Optional[Sequence[Prior]] - what kind of prior distribution to use for latent embeddings - e.g. serotiny.models.vae.priors.IsotropicGaussianPrior\n",
    "kernel_size: int - Kernel size for convolutional filters - e.g. 3\n",
    "encoder_clamp: Optional[int] - whether to clamp outputs from the encoder - e.g. 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff02c22-7f6a-4900-b476-8a49e339d891",
   "metadata": {},
   "source": [
    "Lets train a 3D image VAE on the edge vs non-edge cell dataset. A VAE model config for this data can look like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256783f9-cb87-4541-996f-c59b051f15ae",
   "metadata": {},
   "source": [
    "```yaml\n",
    "_target_: serotiny.models.vae.ImageVAE\n",
    "latent_dim: 512\n",
    "in_channels: 1\n",
    "hidden_channels: [2, 2, 2, 2]\n",
    "max_pool_layers: [2]\n",
    "input_dims: [32, 60, 94] # level 2 image shape\n",
    "x_label: image\n",
    "optimizer:\n",
    "  _partial_: true\n",
    "  _target_: torch.optim.adam.Adam\n",
    "  lr: 0.001\n",
    "  betas:\n",
    "  - 0.9\n",
    "  - 0.999\n",
    "  eps: 1.0e-08\n",
    "  weight_decay: 0\n",
    "  amsgrad: false\n",
    "beta: 1.0\n",
    "non_linearity:\n",
    "  # _target_: torch.nn.SiLU\n",
    "    _target_: torch.nn.ReLU\n",
    "prior:\n",
    "  image: \n",
    "    _target_: serotiny.models.vae.priors.IsotropicGaussianPrior\n",
    "    dimensionality: 512\n",
    "reconstruction_loss:\n",
    "  image: \n",
    "    _target_: torch.nn.modules.loss.MSELoss\n",
    "    reduction: none\n",
    "mode: 3d\n",
    "skip_connections: False\n",
    "kernel_size: 3\n",
    "stride: 1\n",
    "# final_non_linearity: TanH\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1778c8-24fb-47bc-b45c-7e47678c982d",
   "metadata": {},
   "source": [
    "Here, we are embedding the 3D images into a latent space with 512 dimensions, using a convolutional neural network (CNN). The CNN encoder applies 4 sets of convolutional blocks, each comprising 2 filters, with a kernel size of 3, stride 1, padding 0. We apply a max pooling operation with the 3rd convolution operation (index 2). After each convolution, we apply a ReLU non-linearity, followed by a batch norm. For the VAE loss, we use a beta of 1, meaning the total loss is the reconstruction loss + KL divergence loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495761e-ab39-4bfb-9f26-286658063848",
   "metadata": {},
   "source": [
    "#### Changing the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229af91-96e0-4f0c-817c-3edaded52330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the commands we type to be ran from the serotiny project root\n",
    "# (because that's what `serotiny` expects) so we change directories here,\n",
    "# so we can run commands within the notebook\n",
    "import os\n",
    "os.chdir(\"/home/aicsuser/cytodata-hackathon-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb58735-e28e-4495-b4c7-4021685f2855",
   "metadata": {},
   "source": [
    "#### Creating a run name based on the current date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514882d-f782-4623-ab64-fac6034dbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# util to avoid referring to the same run unintentionally\n",
    "now_str = lambda : datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d99c10-d754-4e9a-97f3-23f90efc3b1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Starting a training. Track the training at OR http://mlflow.cytodata.allencell.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163661f-7ba7-4b0e-8fd1-08f21988f963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_name = f\"ritvik_3d_run_{now_str()}\"\n",
    "\n",
    "!serotiny train \\\n",
    "    model=example_vae_3d \\\n",
    "    data=example_dataloader_3d \\\n",
    "    mlflow.experiment_name=cytodata_chapter_vae \\\n",
    "    mlflow.run_name={run_name} \\\n",
    "    trainer.gpus=[0] \\\n",
    "    trainer.max_epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf21f93-12c4-443e-9919-75e9d7f7a018",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a id='apply'></a>5.2 Load and test a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52378457-14cb-41b7-b400-d5baea72f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!serotiny test \\\n",
    "    model=example_vae_3d \\\n",
    "    data=example_dataloader_3d \\\n",
    "    mlflow.experiment_name=cytodata_chapter_vae \\\n",
    "    mlflow.run_name={run_name} \\\n",
    "    trainer/callbacks=vae \\\n",
    "    ++force=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc81b91-242b-4132-ba74-89d5164c4d77",
   "metadata": {},
   "source": [
    "### Retrieving predictions from MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61174ab-26b8-4f37-9058-a268dd9d072c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from serotiny.ml_ops.mlflow_utils import download_artifact\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow.mlflow.svc.cluster.local\")\n",
    "\n",
    "with download_artifact(\"dataframes/embeddings.csv\", experiment_name=\"cytodata_chapter_vae\", run_name=run_name) as path:\n",
    "    embeddings = pd.read_csv(path)\n",
    "    \n",
    "with download_artifact(\"dataframes/stats_per_dim_test.csv\", experiment_name=\"cytodata_chapter_vae\", run_name=run_name) as path:\n",
    "    kl_per_dimension = pd.read_csv(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf029a2-3473-4f8c-a8ee-00db53684ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dimension ranks based on KLD values\n",
    "from cytodata_aics.vae_utils import get_ranked_dims\n",
    "ranked_z_dim_list, mu_std_list, mu_mean_list = get_ranked_dims(kl_per_dimension, 0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76a2f6-e120-4cc4-a32a-a8363019c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_z_dim_list = [f\"mu_{i}\" for i in ranked_z_dim_list]\n",
    "updated_ranks = [f\"mu_{i+1}\" for i in range(8)]\n",
    "embeddings = embeddings[[i for i in embeddings.columns if i in ranked_z_dim_list] + ['CellId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b5c18-216e-4b4d-8112-08d77f5cc50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank embeddings from 1 to 8\n",
    "rename_cols = {}\n",
    "for i, j in zip(ranked_z_dim_list, updated_ranks):\n",
    "    rename_cols[i] = j\n",
    "embeddings.rename(columns = rename_cols, inplace=True)\n",
    "embeddings = embeddings.reindex(sorted(embeddings.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa6b5f-0009-42e5-ada2-6153592bba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.merge(cells_edgeVSnoedge[['CellId'] + \n",
    "                                                 [i for i in cells_edgeVSnoedge.columns if \"shape_mode\" in i] + \n",
    "                                                ['nuclear_volume', 'nuclear_height', 'nuclear_surface_area']], on = 'CellId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68aeaf-65d0-477f-89ce-124a4651d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make correlation heatmap\n",
    "sns.heatmap(embeddings[[i for i in embeddings.columns if i != 'CellId']].corr(), vmin=-1, vmax=1, cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294057e-a447-4fed-be37-16e30efa86c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a id='train2D'></a> 5.3 Train a VAE on 2D images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e22728-9bc5-4675-97c0-8ab880899b28",
   "metadata": {},
   "source": [
    "For training 2D images, we can use the 2D equivalent configs for both the data and model, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8aab5-b129-46e5-90e3-5b2dbb877223",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"ritvik_2d_run_{now_str()}\"\n",
    "\n",
    "!serotiny train \\\n",
    "    model=example_vae_2d \\\n",
    "    data=example_dataloader_2d \\\n",
    "    mlflow.experiment_name=cytodata_chapter_vae \\\n",
    "    mlflow.run_name={run_name} \\\n",
    "    trainer.gpus=[0] \\\n",
    "    trainer.max_epochs=100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
