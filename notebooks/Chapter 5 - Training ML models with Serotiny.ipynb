{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bed1c8-fc44-4369-b188-4170a5b9e017",
   "metadata": {},
   "source": [
    "Chapter 5: Training ML models with Serotiny\n",
    "Suggested: Alex, Gui\n",
    "- Quick explanation of serotinyâ€™s yaml-based task formulation\n",
    "- Show how one can start a simple training based on 2D images to classify, e.g. edge vs. non-edge cells\n",
    "- Show how one can load and apply the trained model\n",
    "- Show how to bring in a pretrained model (2D RESNET)\n",
    "- Show that we can use the latent space from 3D images (which has been precomputed and stored)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636df5b1-d79a-4cc5-b907-64d4c0b74e90",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Serotiny in a nutshell**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c935e8-b8df-43f7-b869-ff3e2d6621d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "`serotiny` is a Python package and framework to help you create configurable and reproducible DL projects. It uses [hydra](https://hydra.cc/) for configurability, [MLFlow](https://mlflow.org/) for experiment tracking,\n",
    "and [Pytorch Lightning](https://pytorchlightning.ai/) for DL model training/testing/predictions.\n",
    "\n",
    "## **Project structure**\n",
    "With `serotiny` a DL project has a predefined structure (which this repo already complies with). To start a new project with the appropriate structure, you can use the [serotiny-project cookiecutter](https://github.com/allencellmodeling/serotiny-project-cookiecutter)\n",
    "\n",
    "A serotiny project contains a Python package, and a config folder. This config folder is composed of 5 config groups:\n",
    "\n",
    "- `data` : where we configure access to datasets\n",
    "\n",
    "- `model` : where we define and parameterize models/networks\n",
    "\n",
    "- `trainer` : where we setup the Pytorch Lightning trainer\n",
    "\n",
    "- `trainer/callbacks` : where we (optionally) add a list of callbacks to be run in train/test/prediction\n",
    "\n",
    "- `mlflow`: where we configure access to a MLFlow server, where our experiments and results will be tracked and stored\n",
    "\n",
    "## **`serotiny` commands**\n",
    "Aside from the predefined structure and config folder, `serotiny` has set of commands which know how to read a project's configuration (and override it)\n",
    "and execute DL tasks.\n",
    "\n",
    "For example, we could train a model using the a model config called `my_classifier` (which would live in `config/model/my_classifier.yaml`), and a data config\n",
    "called `my_train_data` (which would live in `config/data/my_train_data.yaml`) and overriding some of the `mlflow` config parameters.\n",
    "<br><small>Note: Because we didn't specify a top-level `mlflow` config, i.e. we didn't do `mlflow=...`, `serotiny` will use the default config, which lives in `config/mlflow/default.yaml`</small>\n",
    "\n",
    "```\n",
    "$ serotiny train model=my_classifier data=my_train_data mlflow.experiment_name=some_experiment mlflow.run_name=1st_run\n",
    "```\n",
    "\n",
    "Once the model finishes training, we could use it to make predictions on a different dataset, configured in `my_predict_data`\n",
    "\n",
    "```\n",
    "$ serotiny predict model=my_classifier data=my_predict_data mlflow.experiment_name=some_experiment mlflow.run_name=1st_run\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c5ca9-6c42-4c08-a6ed-3b37f5cf7251",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Getting started**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ecce7-4c5f-4e30-8235-7714c471e1e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Creating a dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43473233-c3d4-4d95-be6f-bc93c511fcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"bfio\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"bfio.backends\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"aicsimageio\").setLevel(logging.ERROR)\n",
    "\n",
    "from upath import UPath as Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nbvv\n",
    "\n",
    "from serotiny.io.image import image_loader\n",
    "from cytodata_aics.io_utils import rescale_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f337331-424d-4139-b2e8-06958c139950",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the manifest and explore dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e619ed29-e90a-4669-b212-302b75a4371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_df = pd.read_parquet(\"s3://variance-dataset/processed/manifest.parquet\")\n",
    "print(f\"Number of cells: {len(cells_df)}\")\n",
    "print(f\"Number of columns: {len(cells_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96afa7-d31c-4f67-9f76-0736439342eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make a simple dataset of edge vs. non-edge cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c8837-2b7c-408c-af79-bd2b12798e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serotiny.transforms.dataframe.transforms import split_dataframe\n",
    "\n",
    "Path(\"/home/aicsuser/serotiny_data/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n = 1000 # number of cells per class\n",
    "cells_edgeVSnoedge = cells_df.groupby(\"edge_flag\").sample(n)\n",
    "\n",
    "# Add the train, test and validate split\n",
    "cells_edgeVSnoedge = split_dataframe(dataframe=cells_edgeVSnoedge, train_frac=0.7, val_frac=0.2, return_splits=False)\n",
    "\n",
    "cells_edgeVSnoedge.to_csv(\"/home/aicsuser/serotiny_data/cells_edgeVSnoedge.csv\") \n",
    "print(f\"Number of cells: {len(cells_edgeVSnoedge)}\")\n",
    "print(f\"Number of columns: {len(cells_edgeVSnoedge.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b3961d-3044-4fa2-bebd-8c6c36b46dcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize some non-edge cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60238f52-54a4-44ba-add4-bba514723b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_cell = cells_edgeVSnoedge[cells_edgeVSnoedge.edge_flag == 0].sample(1).iloc[0]\n",
    "\n",
    "img = image_loader(\n",
    "    some_cell.registered_path,\n",
    "    transform=rescale_image,\n",
    "    return_as_torch=False\n",
    ")\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b99cf-51c5-435c-a32e-2a2d8b219303",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[1].max(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d3646-75c0-4c71-a46c-dae194bfce75",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize some edge cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e99e5-672c-4117-b63a-49705f7c1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_cell = cells_edgeVSnoedge[cells_edgeVSnoedge.edge_flag == 1].sample(1).iloc[0]\n",
    "\n",
    "img = image_loader(\n",
    "    some_cell.registered_path,\n",
    "    transform=rescale_image,\n",
    "    return_as_torch=False\n",
    ")\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9d48b-78f4-43e7-aa6e-5de056b40a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[1].max(axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477881f-f73a-4fb1-846e-6e3846e82f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_cell[[col for col in some_cell.index if \"fits\" in col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45979e4-dabb-4e19-8dee-514eeccfd26f",
   "metadata": {},
   "source": [
    "## **Configuring serotiny**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a7374-7934-47ab-a657-47d1c4a6ba76",
   "metadata": {},
   "source": [
    "**TODO** general blurp about config syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb247cdd-4d37-4b5f-a727-119cec421cdd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### `data` config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410cdbc5-ad58-4fdc-9f97-0575472ee3cd",
   "metadata": {},
   "source": [
    "As refered to above, `serotiny` requires you to have configured 5 modules. The first one we will look into is the `data` module.\n",
    "\n",
    "**TODO** Incrementally build up this yaml here in the markdown\n",
    "\n",
    "```\n",
    "_target_: serotiny.datamodules.ManifestDatamodule\n",
    "\n",
    "path: /home/aicsuser/serotiny_data/cells_edgeVSnoedge.csv\n",
    "\n",
    "batch_size: 64\n",
    "num_workers: 1\n",
    "loaders:\n",
    "  id:\n",
    "    _target_: serotiny.io.dataframe.loaders.LoadColumn\n",
    "    column: CellId\n",
    "    dtype: int\n",
    "  class:\n",
    "    _target_: serotiny.io.dataframe.loaders.LoadColumn\n",
    "    column: edge_flag\n",
    "    dtype: float32\n",
    "  image:\n",
    "    _target_: serotiny.io.dataframe.loaders.LoadImage\n",
    "    column: max_projection_z\n",
    "    select_channels: ['membrane']  \n",
    "    \n",
    "split_column: \"split\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566cb649-787f-4457-8e63-2b47fe52e0b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `model` config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5f48f-47a4-4e5b-9275-bb4aa96ea34b",
   "metadata": {},
   "source": [
    "The next module we'll  configure is the `model` module.\n",
    "\n",
    "**TODO** Incrementally build up this yaml here in the markdown\n",
    "\n",
    "**TODO/Recommendation** Let's use the long-form yaml config, instead of yaml variables (and keep this version under the Advanced subsection below)\n",
    "\n",
    "\n",
    "```\n",
    "_aux_: \n",
    "  _a: &hidden_channels 4\n",
    "  _b: &kernel_size 3\n",
    "  _c: &conv_block\n",
    "    _target_: torch.nn.Sequential\n",
    "    _args_:\n",
    "      - _target_: torch.nn.LazyConv2d\n",
    "        out_channels: *hidden_channels\n",
    "        kernel_size: *kernel_size\n",
    "        stride: 1\n",
    "      - _target_: torch.nn.LeakyReLU\n",
    "      - _target_: torch.nn.LazyBatchNorm2d\n",
    "\n",
    "_target_: serotiny.models.BasicModel\n",
    "x_label: image\n",
    "y_label: class\n",
    "network:\n",
    "  _target_: torch.nn.Sequential\n",
    "  _args_:\n",
    "    - *conv_block\n",
    "    - *conv_block\n",
    "    - *conv_block\n",
    "    - _target_: serotiny.networks.layers.Flatten\n",
    "    - _target_: torch.nn.LazyLinear\n",
    "      out_features: 1\n",
    "    - _target_: torch.nn.Sigmoid\n",
    "    \n",
    "loss:\n",
    "  _target_: torch.nn.BCELoss\n",
    "  \n",
    "# a function used by `serotiny predict` to store the results of feeding data through the model\n",
    "save_predictions:\n",
    "  _target_: cytodata_aics.model_utils.save_predictions_classifier\n",
    "  _partial_: true\n",
    "\n",
    "# fields to include in the output for each batch\n",
    "fields_to_log:\n",
    "  - id\n",
    " \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387142ab-4d2f-4dd2-9c4f-3718f2c0e583",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Advanced version**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534c2cc-f6a9-4144-8796-7977ef388efc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "This version uses some YAML tricks and the `_aux_` section (which is ignored by `serotiny`) to\n",
    "more flexibly build models\n",
    "\n",
    "```\n",
    "_aux_: \n",
    "  _a: &hidden_channels 4\n",
    "  _b: &kernel_size 3\n",
    "  _c: &conv_block\n",
    "    _target_: torch.nn.Sequential\n",
    "    _args_:\n",
    "      - _target_: torch.nn.LazyConv2d\n",
    "        out_channels: *hidden_channels\n",
    "        kernel_size: *kernel_size\n",
    "        stride: 1\n",
    "      - _target_: torch.nn.LeakyReLU\n",
    "      - _target_: torch.nn.LazyBatchNorm2d\n",
    "\n",
    "_target_: serotiny.models.BasicModel\n",
    "x_label: image\n",
    "y_label: class\n",
    "network:\n",
    "  _target_: torch.nn.Sequential\n",
    "  _args_:\n",
    "    - *conv_block\n",
    "    - *conv_block\n",
    "    - *conv_block\n",
    "    - _target_: serotiny.networks.layers.Flatten\n",
    "    - _target_: torch.nn.LazyLinear\n",
    "      out_features: 1\n",
    "    - _target_: torch.nn.Sigmoid\n",
    "    \n",
    "loss:\n",
    "  _target_: torch.nn.BCELoss\n",
    "  \n",
    "  \n",
    "# a function used by `serotiny predict` to store the results of feeding data through the model\n",
    "save_predictions:\n",
    "  _target_: cytodata_aics.model_utils.save_predictions_classifier\n",
    "  _partial_: true\n",
    "\n",
    "# fields to include in the output for each batch\n",
    "fields_to_log:\n",
    "  - id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb1951-2c90-47d5-beaf-4dca07dfef0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### `trainer` config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2aa54-03a8-42f3-9d52-badc651eee04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "####  `trainer/callbacks` config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108baafa-1195-4ff4-a7d6-7781a8a93d9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `mlflow` config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb307c91-9751-4aba-ae47-b7ed2af54fa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Trainining a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d470202-420d-471e-a16c-840d4e6d6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the commands we type to be with respect to the project root\n",
    "# (because that's what `serotiny` expects) so we change directories here,\n",
    "# so we can run commands within the notebook\n",
    "import os\n",
    "os.chdir(\"/home/aicsuser/cytodata-hackathon-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314aeaa-d1de-483e-a675-7da4e92e0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# util to avoid referring to the same run unintentionally\n",
    "now_str = lambda : datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f90e95-ac6a-4995-8c5f-b2f269153afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_name = f\"some_2d_run_{now_str()}\"\n",
    "\n",
    "!serotiny train \\\n",
    "    model=example_classifier_2d \\\n",
    "    data=example_dataloader_2d \\\n",
    "    mlflow=internal_mlflow \\\n",
    "    mlflow.experiment_name=cytodata_chapter5 \\\n",
    "    mlflow.run_name={run_name} \\\n",
    "    trainer.gpus=[0] \\\n",
    "    trainer.max_epochs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35ac9a-5346-434a-8c38-743ea0f0c2e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Using  a trained model to make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c487b8a-b858-445d-af79-4a6a332ba133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!serotiny predict \\\n",
    "    model=example_classifier_2d \\\n",
    "    data=example_dataloader_2d \\\n",
    "    mlflow=internal_mlflow \\\n",
    "    mlflow.experiment_name=cytodata_chapter5 \\\n",
    "    mlflow.run_name={run_name} \\\n",
    "    trainer.gpus=[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73172d20-29ea-4e12-8094-dbe7bab4e21e",
   "metadata": {},
   "source": [
    "### Retrieving predictions from MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05b664-e875-4356-8b5c-9479d72a4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from serotiny.ml_ops.mlflow_utils import download_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6886eb-9519-4e18-a8cb-bf92987630dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://mlflow.a100.int.allencell.org\")\n",
    "\n",
    "with download_artifact(\"predictions/model_predictions.csv\", experiment_name=\"cytodata_chapter5\", run_name=\"some_2d_run_20220913_205333\") as path:\n",
    "    predictions_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa1dd3-4dca-4af1-8674-38959cea7b09",
   "metadata": {},
   "source": [
    "### **Training a 3d model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7901171-806f-4621-a2c8-f05ec9ff3ede",
   "metadata": {},
   "source": [
    "**TODO** Make it an exercise to create the 3d versions of the configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba4506-7405-4a7a-8b5a-a76ab648d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"some_3d_run_{now_str()}\"\n",
    "\n",
    "!serotiny train \\\n",
    "    model=example_classifier_3d \\\n",
    "    data=example_dataloader_3d \\\n",
    "    mlflow=internal_mlflow \\\n",
    "    mlflow.experiment_name=cytodata_chapter5 \\\n",
    "    mlflow.run_name={run_name} \\\n",
    "    trainer.gpus=[0] \\\n",
    "    trainer.max_epochs=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8792ca-8d57-48d0-af6d-838eddff798b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
